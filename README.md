# RL_TD_Baseline
强化学习最简单的入门，实验环境使用一维线性环境，策略评估采用时序差分方法。

实验环境
0-A-B-C-D-E-1
该环境是一个最简单的马尔可夫决策过程，环境一共有A\B\C\D\E五个状态，智能体在环境中只能左移或者右移，初始状态为C，当
智能体到达最左端或者最右端的时候该回合结束。如果智能体到达最右端的话会获得1的奖励，此外奖励均为0。

如果该任务是无折扣的，且每次都是随机选择动作进行左移或者右移，那么A-E每个状态的真实值函数分别为1/6,2/6,3/6,4/6,5/6。

证明:

约定V(S)为某个状态的真实值函数，那么就有

V(A) = 1/2 * 0    + 1/2 * V(B)
V(B) = 1/2 * V(A) + 1/2 * V(C)
V(C) = 1/2 * V(B) + 1/2 * V(D)
V(D) = 1/2 * V(C) + 1/2 * V(E)
V(E) = 1/2 * V(D) + 1/2 * 1

转化为矩阵形式

E * V = A * V + b //其中 E 为单位阵，A=[0 1/2 0 0 0;1/2 0 1/2 0 0;0 1/2 0 1/2 0; 0 0 1/2 0 1/2;0 0 0 1/2 0]   b = [0 0 0 0 1/2]

由上可得:
V = [1/6 2/6 3/6 4/6 5/6]


